
<div align="center">
  <h1> Dubwiz : A Multilingual Video Dubbing System </h1>
  <img width="640" alt="fefe" src="https://github.com/Om-Gujarathi/SIH_2023/assets/98649066/3ad98653-093b-459c-bc26-312e2265f908">

</div>
<br>


Introducing an innovative solution designed to bridge the gap in disseminating government policies and schemes to rural India. Our Web-based Video Dubbing Platform harnesses advanced transformer models, offering a transformative way to convey vital information. It's as simple as uploading a video or YouTube link to our portal, where our cutting-edge technologies come into play. ([Video Demonstration](https://youtu.be/yDMNfBEoQrQ?si=f4XlWfA-mWXx6eka))

## Overall Workflow of Project
![FlowChart](https://github.com/om9011/Video-Dubbing/assets/114930828/e7155ea0-a65d-4f68-bdc7-46f9b92337ad)


## Project Structure

```
project-root/
│
├── backend/
│   ├── server.py                 # Flask server script
│   ├── requirements/
│   │   └── requirements.txt      # Backend Python dependencies
│   ├── final/                    # Directory to store final dubbed video
│   ├── output/                   # Directory to store output files (subtitles, audio)
│   └── ...
│
└── frontend/
    ├── public/
        └── index.html
    ├── src/
    │   └── ...                    # ReactJS frontend source files
    ├── package.json               # Frontend Node.js dependencies
    └── ...
```

## Frontend (ReactJS)

- The frontend of this project is developed using ReactJS. You'll need Node.js and npm (Node Package Manager) to install and manage the frontend dependencies. Ensure you have Node.js installed, then navigate to the \`frontend\` directory and run:

```bash
npm install
```

This will install all the required frontend dependencies listed in \`frontend/package.json\`.

- To run the frontend, use the following commands:

```bash
cd client
```
```bash
npm start
```

## Backend Requirements

To run the backend of this project, you'll need the following Python libraries:

- torch
- torchaudio
- transformers
- datasets
- moviepy
- requests
- Flask
- gunicorn
- python-dotenv
- soundfile
- librosa

These requirements are specified in the \`requirements.txt\` file provided in the \`backend\` folder. You can install these dependencies using pip:

```bash
pip install -r backend/requirements.txt
```

To run the backend server, use the following commands:

```bash
cd server
```
```bash
python server.py
```





## Usage

1. **Setting up the Backend**:
   - Install Python dependencies using \`pip\` as described above.
   - Start the Flask server by running \`python backend/server.py\` from the project root directory.

2. **Setting up the Frontend**:
   - Install frontend dependencies using \`npm install\` from the \`frontend\` directory.
   - Start the React development server to run the frontend interface.

3. **Workflow**:

   - **Frontend**:
     - User uploads a video file through the frontend interface.

   - **Backend**:
     - The backend receives the uploaded video file.
     - The video file is processed to detach the audio using ***<b>MoviePy library.</b>***
     - The extracted audio is saved in the \`backend/output\` directory.

     - The extracted audio is transcribed into English text using ***<b>OpenAI's Whisper model.</b>***
     - The English text is translated into the desired regional language using ***<b>Facebook's mBART model (\`facebook/mbart-large-50-one-to-many-mmt\`).</b>***
     - The translated text is converted back into audio using a speech synthesis model like ***<b>Silero.</b>***

     - The original video file is combined with the newly generated audio to create the final dubbed video.
     - The final dubbed video is saved in the ***\`backend/final\`*** directory.

## Sample Input Video

You can use the following sample input video for testing the video dubbing application:

[Sample Input Video]()

## Sample Output Video

Here is an example of the output video generated by the video dubbing application:

[Sample Output Video]()


## ML Models used :

- **[Open AI Whisper](https://github.com/openai/whisper):** Accurate audio-to-text transcription.
- **[MBart](https://huggingface.co/facebook/mbart-large-50):** Seamless text translation into desired Indian languages.
- **[Silero](https://github.com/snakers4/silero-models):** Authentic audio conversion in multiple accents.
- **[Wave2Lip](https://github.com/Rudrabha/Wav2Lip):** Lip Sync Audio over a video.



